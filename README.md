# 动手学深度学习 李沐 dive-into-deep-learning

李沐老师的课程中源码都是用jupyter notebook写的；这里全部使用pycharm编辑器来编程，改写为py格式。  
希望可以记录课程的学习过程，同时能帮助他人。

### 课程相关资料
1. 课程的直播地址：http://courses.d2l.ai/zh-v2/
2. 课程的课件地址：https://zh-v2.d2l.ai/
3. 另一个可参考的笔记：https://tangshusen.me/Dive-into-DL-PyTorch

### 本笔记的目录
##### ch01. 预备知识  
1.1. 数据操作
1.2. 数据预处理
1.3. 线性代数
1.4. 微分
1.5. 自动求导                       
1.6. 概率 
##### ch02. 线性神经网络  
2.1. 线性回归
2.2. 线性回归的从零开始实现
2.3. 线性回归的简洁实现  
2.4. softmax回归  
2.5. 图像分类数据集
2.6. softmax回归的从零开始实现
2.7. softmax回归的简洁实现
##### ch03. 多层感知机  
3.1. 多层感知机
3.2. 多层感知机的从零开始实现
3.3. 多层感知机的简洁实现
3.4. 模型选择、欠拟合和过拟合
3.5. 权重衰减
3.6. Dropout
3.7. 正向传播、反向传播和计算图  
3.8. 数值稳定性和模型初始化  
3.9. 环境和分布偏移  
3.10. 实战 Kaggle 比赛：预测房价   
##### ch04. 深度学习计算  
4.1. 层和块
4.2. 参数管理
4.3. 延后初始化  
4.4. 自定义层
4.5. 读写文件
4.6. GPU  
##### ch05. 卷积神经网络  
5.1. 二维卷积层  
5.2. 填充和步幅  
5.3. 多输入多输出通道
5.4. 池化层
5.5. 卷积神经网络（LeNet）  
5.6. 深度卷积神经网络（AlexNet）  
5.7. 使用重复元素的网络（VGG）  
5.8. 网络中的网络（NiN）  
5.9. 含并行连结的网络（GoogLeNet）  
5.10. 批量归一化  
5.11. 残差网络（ResNet）  
5.12. 稠密连接网络（DenseNet）  
##### ch06.  计算机视觉
6.1. 图像增广  
6.2. 微调  
6.3. 目标检测和边界框  
6.4. 锚框   
6.5. 多尺度目标检测  
6.6. 目标检测数据集（皮卡丘）   
6.7. 单发多框检测（SSD）  
6.8. 区域卷积神经网络（R-CNN）系列  
6.9. 语义分割和数据集  
6.10. 转置卷积  
6.11. 全卷积网络  
6.12. 样式迁移   
##### ch07.  循环神经网络
7.1. 语言模型  
7.2. 循环神经网络  
7.3. 语言模型数据集（周杰伦专辑歌词）  
7.4. 循环神经网络的从零开始实现  
7.5. 循环神经网络的简洁实现  
7.6. 通过时间反向传播  
7.7. 门控循环单元（GRU）  
7.8. 长短期记忆（LSTM）  
7.9. 深度循环神经网络  
7.10. 双向循环神经网络  
7.11. 机器翻译与数据集  
7.12. 编码器-解码器结构

